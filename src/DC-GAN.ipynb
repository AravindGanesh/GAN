{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional GAN \n",
    "Reference : https://arxiv.org/abs/1511.06434"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target \n",
    "DC GAN on celebA, cifar-10, cifar-100 datasets\n",
    "###### To report\n",
    "+ Train - parameters and architecture \n",
    "+ saved weights for 3 datasets \n",
    "+ loss, number of epochs\n",
    "+ generated images : modes vs quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train, x_test = x_train/255, x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plan\n",
    "\n",
    "+ read to tf.Dataset() format\n",
    "+ model class()\n",
    "+ `noise(batch_size, dim, distribution='uniform'):`  \n",
    "+ def `generator(z):` returns image\n",
    "+ def `discriminator(img):` returns logits\n",
    "+ def `batch_norm` : returns normalized batch\n",
    "+ def `**LOSS**(real, fake):` returns losses of G and D\n",
    "+ def `save():` saves model to a file \n",
    "+ def `load(filename):` loads saved model\n",
    "+ def `generate_images(num_imgs)` - function to generate from trained model -\n",
    "+ def `evaluate(x_test)`\n",
    "\n",
    "#### Architecture guidelines for stable Deep Convolutional GANs - reference: GAN paper\n",
    "+ Replace any pooling layers with strided convolutions (discriminator) and fractional-strided convolutions (generator).\n",
    "+ Use batchnorm in both the generator and the discriminator. _Do not apply batchnorm to G output layer and D input layer_\n",
    "+ Remove fully connected hidden layers for deeper architectures.\n",
    "+ Use ReLU activation in generator for all layers except for the output, which uses Tanh.\n",
    "+ Use LeakyReLU activation in the discriminator for all layers. In the LeakyReLU, the slope of the leak was set to 0.2 in all models.\n",
    "+ Scale images to range of $[-1,1]$\n",
    "+ minibatch stocastic gradient - batch_size = 128\n",
    "+ All weights were initialized from a zero-centered Normal distribution with standard deviation 0.02.\n",
    "\n",
    "+ Adam optimizer: learning_rate = 0.0002, Î²1 = 0.5\n",
    "+ We found global average pooling increased model stability but hurt convergence speed. A middle ground of directly connecting the highest convolutional features to the input and output respectively of the generator and discriminator worked well.\n",
    "+ simple image de-duplication process. We fit a 3072-128-3072 de-noising dropout regularized RELU autoencoder on 32x32 downsampled center-crops of training examples.\n",
    "+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-15-434c16df7337>, line 200)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-434c16df7337>\"\u001b[0;36m, line \u001b[0;32m200\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class DC_GAN():\n",
    "    def __init__(self, sess, real_img_dim, gen_img_dim, noise_dim, batch_size, num_channels=3):\n",
    "        self.sess = sess\n",
    "        self.noise_dim = noise_dim\n",
    "        self.D_input_dim = real_img_dim\n",
    "        self.G_output_dim = gen_img_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.channels = num_channels\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "    def noise(self, pdf='uniform'): \n",
    "        '''\n",
    "        Inputs: batch size while training, dimension of noise\n",
    "        returns random sample from the distribution - pdf (uniform by default)\n",
    "        '''\n",
    "        if pdf=='uniform':\n",
    "            return tf.random_uniform(minval=-1, maxval=1, shape=(self.batch_size, self.noise_dim), name='z')\n",
    "        if pdf=='normal':\n",
    "            return tf.random_normal(mean=0, stddev=1, shape=(self.batch_size, self.noise_dim), name='z')\n",
    "    \n",
    "    def batch_norm(self, batch):\n",
    "        return tf.contrib.layers.batch_norm(inputs=batch,\n",
    "            decay=0.9,\n",
    "            updates_collections=None,\n",
    "            epsilon=1e-5,\n",
    "            scale=True,\n",
    "            is_training=True\n",
    "            )\n",
    "    \n",
    "    def add_conv_layer(self, inputs, filter_size, in_channels, out_channels, scope_name, _batch_norm=True):\n",
    "        with tf.variable_scope(scope_name):\n",
    "            shape = [filter_size, filter_size, in_channels, out_channels]\n",
    "            weights = tf.Variable(tf.truncated_normal(shape, stddev=0.02), trainable=True)\n",
    "            biases = tf.Variable(tf.constant(0.05, shape=[out_channels]), trainable=True)\n",
    "            \n",
    "            layer = tf.nn.conv2d(\n",
    "                input=inputs,\n",
    "                filter=weights,\n",
    "                strides=[1, 2, 2, 1],     \n",
    "          errD_fake = self.d_loss_fake.eval({\n",
    "              self.z: batch_z, \n",
    "              self.y:batch_labels\n",
    "          })\n",
    "                padding='SAME') + biases\n",
    "            if _batch_norm: layer = self.batch_norm(layer)\n",
    "            layer = tf.nn.leaky_relu(layer, alpha=0.2)\n",
    "            return layer, weights, biases\n",
    "            \n",
    "    def add_conv_transpose_layer(self,inputs,filter_size,in_channels,out_channels,scope_name,activation,_batch_norm=True):\n",
    "        with tf.variable_scope(scope_name):\n",
    "            shape = [filter_size, filter_size, out_channels, in_channels]\n",
    "            weights = tf.Variable(tf.truncated_normal(shape, stddev=0.02), trainable=True)\n",
    "            biases = tf.Variable(tf.constant(0.05, shape=[out_channels]), trainable=True)\n",
    "\n",
    "            layer = tf.nn.conv2d_transpose(\n",
    "                input=inputs,\n",
    "                filter=weights,\n",
    "                strides=[1, 2, 2, 1],\n",
    "                padding='SAME') + biases\n",
    "            if _batch_norm: layer = self.batch_norm(layer)\n",
    "            if activation == 'relu': layer = tf.nn.relu(layer)\n",
    "            elif activation == 'tanh': layer = tf.nn.tanh(layer)\n",
    "\n",
    "            return layer, weights, biases\n",
    "\n",
    "    def discriminator(self, img):\n",
    "        scope_name='discriminator'\n",
    "        h1, w1, b1 = self.add_conv_layer(\n",
    "            inputs = img,\n",
    "            filter_size=5,\n",
    "            in_channels=self.num_channels,\n",
    "            out_channels=64,\n",
    "            _batch_norm=False,\n",
    "            scope_name=scope_name\n",
    "        )\n",
    "        h2, w2, b2 = self.add_conv_layer(\n",
    "            inputs=h1,\n",
    "            filter_size=5,\n",
    "            in_channels=64,\n",
    "            num_filters=128,\n",
    "            scope_name=scope_name\n",
    "        )\n",
    "        h3, w3, b3 = self.add_conv_layer(\n",
    "            inputs=h2,\n",
    "            filter_size=5,\n",
    "            in_channels=128,\n",
    "            out_channels=256,\n",
    "            scope_name=scope_name,\n",
    "        )\n",
    "        logits = tf.layers.dense(\n",
    "            inputs=tf.reshape(h3, shape=[self.batch_size, -1]),\n",
    "            units=1,\n",
    "            use_bias=True,\n",
    "            kernel_initalizer=tf.contrib.layers.xavier_initializer()\n",
    "        )\n",
    "        return logits\n",
    "        \n",
    "    def generator(self, z):\n",
    "        scope_name = 'generator'\n",
    "        _z = tf.layers.dense(\n",
    "            inputs=z,\n",
    "            units=4*4*1024,\n",
    "            use_bias=True,\n",
    "            kernel_initalizer=tf.contrib.layers.xavier_initializer()\n",
    "        ) # projection of z to 4x4x1024 layer (linear)\n",
    "        h1 = tf.reshape(_z, [-1, 4,4,1024])\n",
    "        h2, w2, b2 = self.add_conv_transpose_layer(\n",
    "            inputs=h1,\n",
    "            filter_size=5,\n",
    "            in_channels=1024,\n",
    "            out_channels=512,\n",
    "            scope_name=scope_name,\n",
    "            activation='relu'\n",
    "        )\n",
    "        h3, w3, b3 = self.add_conv_transpose_layer(\n",
    "            inputs=h2,\n",
    "            filter_size=5,\n",
    "            in_channels=512,\n",
    "            out_channels=256,\n",
    "            scope_name=scope_name,\n",
    "            activation='relu'\n",
    "        )\n",
    "        G_out, w4, b4 = self.add_conv_transpose_layer(\n",
    "            inputs=h3,\n",
    "            filter_size=5,\n",
    "            in_channels=256,\n",
    "            num_filters=self.num_channels,\n",
    "            _batch_norm=False,\n",
    "            scope_name=scope_name,\n",
    "            activation='tanh'\n",
    "        )\n",
    "        return G_out\n",
    "    \n",
    "    def generate_imgs(self, num_imgs):\n",
    "        z = self.noise(num_imgs, self.noise_dim)\n",
    "        gen_imgs = self.generator(z)\n",
    "        return gen_imgs\n",
    "        \n",
    "    def compile_model(self, real_imgs, z):\n",
    "        # tf.reset_default_graph()\n",
    "        # self.real_imgs = tf.placeholder(dtype=tf.float32,shape=[self.batch_size]+ self.real_img_dim,name='real')\n",
    "        # self.z = tf.placeholder(dtype=tf.float32, shape=[self.batch_size, self.noise_dim], name='noise')\n",
    "        self.fake_imgs = self.generator(z)\n",
    "        self.logits_real = self.discriminator(real_imgs)\n",
    "        self.logits_fake = self.discriminator(self.fake_imgs)\n",
    "        self.D_loss_real = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=self.logits_real, labels=tf.ones_like(self.logits_real))\n",
    "        self.D_loss_fake = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=self.logits_fake, labels=tf.zeros_like(self.logits_fake))\n",
    "        self.D_loss = tf.reduce_mean(self.D_loss_real) + tf.reduce_mean(self.D_loss_fake)\n",
    "        self.G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=self.logits_fake, labels=tf.ones_like(self.logits_fake)))\n",
    "        self.D_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'discriminator')\n",
    "        self.G_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'generator')\n",
    "    \n",
    "    def preprocessing(self, x):\n",
    "        return 2*x - 1;\n",
    "    \n",
    "    def train(self, real_data, learning_rate=0.0002, beta1=0.5, epochs):\n",
    "        # create tf.data.Dataset() instance\n",
    "        train_data = tf.data.Dataset.from_tensor_slices(real_data) \n",
    "        train_data = train_data.map(self.preprocessing, num_parallel_calls=self.batch_size)\n",
    "        \n",
    "        def noise_generator():\n",
    "            _z = self.noise()\n",
    "            yield _z\n",
    "        z_sample = tf.data.Dataset.from_generator(generator=noise_generator, output_types=(tf.float32)) \n",
    "        # D train step\n",
    "        self.D_train = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate,\n",
    "            beta1=beta1).minimize(self.D_loss, var_list=self.D_vars)\n",
    "        # G train step\n",
    "        self.G_train = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate,\n",
    "            beta1=beta1).minimize(self.G_loss, var_list=self.G_vars)\n",
    "        \n",
    "        tf.global_variables_initializer().run()\n",
    "        train_data = train_data.shuffle(\n",
    "            buffer_size=self.batch_size).repeat(count=epochs).batch(batch_size=self.batch_size)\n",
    "        \n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
